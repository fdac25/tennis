{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/miapatrikios/.local/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from tqdm import trange  \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns used: ['ShotHand_encoded', 'ShotType_encoded', 'ServeDirection_encoded', 'ShotDirection_encoded', 'ShotDepth_encoded', 'OutcomeType_encoded', 'ErrorType_encoded', 'Shot']\n",
      "X_next shape: (9350, 10, 8)\n",
      "y_next shape: (9350,)\n",
      "Number of ShotType classes: 10\n",
      "\n",
      "Next-shot distribution by original ShotType:\n",
      " 0 (NA              ) -> 12\n",
      " 1 (drop_shot       ) -> 190\n",
      " 2 (groundstroke    ) -> 7304\n",
      " 3 (half_volley     ) -> 40\n",
      " 4 (lob             ) -> 191\n",
      " 5 (overhead        ) -> 122\n",
      " 6 (serve           ) -> 25\n",
      " 7 (slice           ) -> 1120\n",
      " 8 (swinging_volley ) -> 30\n",
      " 9 (volley          ) -> 316\n",
      "\n",
      "After grouping & dropping NA/unexpected:\n",
      "X_group shape: (9338, 10, 8)\n",
      "Num grouped labels: 9338\n",
      "Grouped classes: ['drop_shot', 'groundstroke', 'lob_overhead', 'serve', 'slice', 'volley_group']\n",
      "Grouped next-shot counts: Counter({1: 7304, 4: 1120, 5: 386, 2: 313, 0: 190, 3: 25})\n"
     ]
    }
   ],
   "source": [
    "# 1. Load CSV\n",
    "csv_path = \"../data/raw/tennis-m-shots-rg.csv\"  \n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Replace NaN with a string so LabelEncoder can handle them\n",
    "df = df.fillna(\"NA\")\n",
    "\n",
    "# 2. Encode categorical features\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "categories = [\n",
    "    'ShotHand',\n",
    "    'ShotType',\n",
    "    'ServeDirection',\n",
    "    'ShotDirection',\n",
    "    'ShotDepth',\n",
    "    'OutcomeType',\n",
    "    'ErrorType',\n",
    "]\n",
    "\n",
    "for col in categories:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# Feature columns for the model (shot-level)\n",
    "# \"Shot\" is numeric already and acts as a positional feature\n",
    "feature_cols = [col + '_encoded' for col in categories] + ['Shot']\n",
    "\n",
    "print(\"Feature columns used:\", feature_cols)\n",
    "\n",
    "\n",
    "rally_cols = ['Date', 'Tournament', 'Player1', 'Player2', 'Point']\n",
    "K = 10 # number of shots we condition on\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for _, grp in df.groupby(rally_cols):\n",
    "    # Ensure shots are in order\n",
    "    grp = grp.sort_values('Shot')\n",
    "\n",
    "    # Need at least K+1 shots in the rally to define \"next shot\"\n",
    "    if len(grp) <= K:\n",
    "        continue\n",
    "\n",
    "    # First K shots as input features\n",
    "    seq_features = grp[feature_cols].iloc[:K].values.astype('float32')  # (K, F)\n",
    "\n",
    "    # ShotType of the (K+1)-th shot as label\n",
    "    next_shottype_encoded = int(grp['ShotType_encoded'].iloc[K])\n",
    "\n",
    "    X_list.append(seq_features)\n",
    "    y_list.append(next_shottype_encoded)\n",
    "\n",
    "# Stack into arrays\n",
    "X_next = np.stack(X_list, axis=0)               # (N, K, F)\n",
    "y_next = np.array(y_list, dtype=np.int64)       # (N,)\n",
    "\n",
    "print(\"X_next shape:\", X_next.shape)  # (num_examples, K, num_features)\n",
    "print(\"y_next shape:\", y_next.shape)  # (num_examples,)\n",
    "\n",
    "num_shottype_classes = df['ShotType_encoded'].nunique()\n",
    "print(\"Number of ShotType classes:\", num_shottype_classes)\n",
    "\n",
    "# Print distribution over original ShotType (encoded)\n",
    "shottype_le = encoders['ShotType']\n",
    "counts_next = Counter(y_next)\n",
    "\n",
    "print(\"\\nNext-shot distribution by original ShotType:\")\n",
    "for encoded_label, count in sorted(counts_next.items()):\n",
    "    label_name = shottype_le.inverse_transform([encoded_label])[0]\n",
    "    print(f\"{encoded_label:2d} ({label_name:16s}) -> {count}\")\n",
    "\n",
    "\n",
    "# 4. Group ShotTypes into coaching categories\n",
    "# Groups:\n",
    "#  - groundstroke\n",
    "#  - slice\n",
    "#  - drop_shot\n",
    "#  - serve\n",
    "#  - volley_group      = {volley, half_volley, swinging_volley}\n",
    "#  - lob_overhead      = {lob, overhead}\n",
    "#  - NA and anything unexpected are dropped\n",
    "\n",
    "volley_group = {\"volley\", \"half_volley\", \"swinging_volley\"}\n",
    "lob_overhead_group = {\"lob\", \"overhead\"}\n",
    "keep_single = {\"groundstroke\", \"slice\", \"drop_shot\", \"serve\"}\n",
    "\n",
    "group_names = []   # labels per example\n",
    "keep_mask = []     # which examples to keep (exclude NA, etc.)\n",
    "\n",
    "for y in y_next:\n",
    "    st_name = shottype_le.inverse_transform([y])[0]\n",
    "    \n",
    "    if st_name == \"NA\":\n",
    "        keep_mask.append(False)\n",
    "        group_names.append(None)\n",
    "        continue\n",
    "    \n",
    "    if st_name in volley_group:\n",
    "        g = \"volley_group\"\n",
    "    elif st_name in lob_overhead_group:\n",
    "        g = \"lob_overhead\"\n",
    "    elif st_name in keep_single:\n",
    "        g = st_name\n",
    "    else:\n",
    "        # anything unexpected, drop\n",
    "        keep_mask.append(False)\n",
    "        group_names.append(None)\n",
    "        continue\n",
    "    \n",
    "    keep_mask.append(True)\n",
    "    group_names.append(g)\n",
    "\n",
    "keep_mask = np.array(keep_mask, dtype=bool)\n",
    "\n",
    "# Filter X and names\n",
    "X_group = X_next[keep_mask]\n",
    "group_names = [g for g in group_names if g is not None]\n",
    "\n",
    "print(\"\\nAfter grouping & dropping NA/unexpected:\")\n",
    "print(\"X_group shape:\", X_group.shape)\n",
    "print(\"Num grouped labels:\", len(group_names))\n",
    "\n",
    "# Encode grouped labels into integers\n",
    "group_le = LabelEncoder()\n",
    "y_group = group_le.fit_transform(group_names)\n",
    "\n",
    "print(\"Grouped classes:\", list(group_le.classes_))\n",
    "print(\"Grouped next-shot counts:\", Counter(y_group))\n",
    "\n",
    "# 5. Save data + encoders\n",
    "# Original 10-class next-shot labels\n",
    "np.save(\"X_next_shottype.npy\", X_next)\n",
    "np.save(\"y_next_shottype.npy\", y_next)\n",
    "\n",
    "# Grouped 6-class next-shot labels\n",
    "np.save(\"X_next_grouped.npy\", X_group)\n",
    "np.save(\"y_next_grouped.npy\", y_group)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_group shape: (9338, 10, 8)\n",
      "y_group shape: (9338,)\n",
      "Train shape: (7470, 10, 8) Test shape: (1868, 10, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:03<00:15,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:07<00:11,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train Loss: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:11<00:08,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Train Loss: 0.3843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:15<00:04,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Train Loss: 0.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:19<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Load grouped data\n",
    "X_group = np.load(\"X_next_grouped.npy\")   # (9338, 10, 8)\n",
    "y_group = np.load(\"y_next_grouped.npy\")   # (9338,)\n",
    "\n",
    "print(\"X_group shape:\", X_group.shape)\n",
    "print(\"y_group shape:\", y_group.shape)\n",
    "\n",
    "# We know from preprocessing that the classes are:\n",
    "class_names = ['drop_shot', 'groundstroke', 'lob_overhead', 'serve', 'slice', 'volley_group']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# 2. Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_group, y_group,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_group\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "# 3. Dataset + DataLoader\n",
    "class NextShotGroupDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)  # (N, 10, 8)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)     # (N,)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = NextShotGroupDataset(X_train, y_train)\n",
    "test_dataset  = NextShotGroupDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "input_size = X_group.shape[2]   # 8\n",
    "hidden_size = 64\n",
    "\n",
    "# 4. LSTM model\n",
    "class NextShotTypeLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.firstLayer = nn.Linear(hidden_size, 32)\n",
    "        self.output = nn.Linear(32, num_classes)\n",
    "    def forward(self, x):\n",
    "        _, (h, c) = self.lstm(x)\n",
    "        x = torch.relu(self.firstLayer(h.squeeze(0)))\n",
    "        return self.output(x)   # logits\n",
    "\n",
    "model = NextShotTypeLSTM(input_size, hidden_size, num_classes)\n",
    "\n",
    "# 5. Class-balanced loss for rare classes\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.arange(num_classes),\n",
    "    y=y_train\n",
    ")\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "sample_weights = class_weights[y_train]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 6. Training loop\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in trange(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy (grouped ShotType): 0.495\n",
      "Top-2 Accuracy (grouped ShotType): 0.887\n",
      "\n",
      "Classification report (Top-1 predictions, grouped labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   drop_shot       0.03      0.11      0.05        38\n",
      "groundstroke       0.87      0.51      0.64      1461\n",
      "lob_overhead       0.27      0.54      0.36        63\n",
      "       serve       1.00      0.60      0.75         5\n",
      "       slice       0.19      0.50      0.27       224\n",
      "volley_group       0.19      0.38      0.25        77\n",
      "\n",
      "    accuracy                           0.49      1868\n",
      "   macro avg       0.42      0.44      0.39      1868\n",
      "weighted avg       0.72      0.49      0.56      1868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluation (Top-1 and Top-2 accuracy)\n",
    "model.eval()\n",
    "all_true = []\n",
    "all_pred_top1 = []\n",
    "\n",
    "correct_top1 = 0\n",
    "correct_top2 = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        logits = model(X_batch)                      \n",
    "\n",
    "        # Top 1 prediction\n",
    "        top1_pred = torch.argmax(logits, dim=1)      \n",
    "\n",
    "        # Top 2 \n",
    "        top2_vals, top2_idx = torch.topk(logits, k=2, dim=1)   #\n",
    "\n",
    "        # Update counters\n",
    "        total += y_batch.size(0)\n",
    "        correct_top1 += (top1_pred == y_batch).sum().item()\n",
    "        # True if label is in {top1, top2}\n",
    "        correct_top2 += ((top2_idx[:, 0] == y_batch) | (top2_idx[:, 1] == y_batch)).sum().item()\n",
    "\n",
    "        # Save for classification report (top-1 only)\n",
    "        all_true.extend(y_batch.cpu().numpy())\n",
    "        all_pred_top1.extend(top1_pred.cpu().numpy())\n",
    "\n",
    "top1_acc = correct_top1 / total\n",
    "top2_acc = correct_top2 / total\n",
    "\n",
    "print(f\"\\nTop-1 Accuracy (grouped ShotType): {top1_acc:.3f}\")\n",
    "print(f\"Top-2 Accuracy (grouped ShotType): {top2_acc:.3f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification report (Top-1 predictions, grouped labels):\")\n",
    "print(classification_report(all_true, all_pred_top1, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
